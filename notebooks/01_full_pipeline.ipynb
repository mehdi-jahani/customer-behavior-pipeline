{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Customer Behavior Analysis – Live Project Report\n",
        "\n",
        "**Scenario:** Small online handmade store; scattered, noisy data.  \n",
        "**Goal:** Extract insights and predict churn using public + internal data.\n",
        "\n",
        "---\n",
        "## 1. Setup and Data Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import sys\n",
        "from pathlib import Path\n",
        "ROOT = Path.cwd().parent if Path.cwd().name == \"notebooks\" else Path.cwd()\n",
        "sys.path.insert(0, str(ROOT))\n",
        "\n",
        "from scripts.extract_synthetic import run as gen_synthetic\n",
        "from config import DATA_RAW, DATA_PROCESSED\n",
        "\n",
        "gen_synthetic(DATA_RAW)\n",
        "print(\"Raw data:\", list(DATA_RAW.glob(\"*.csv\")))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Transform and Single Source of Truth"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scripts.transform import run_all\n",
        "\n",
        "combined = run_all()\n",
        "print(combined.shape)\n",
        "combined.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Exploratory Data Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scripts.eda import run_eda\n",
        "\n",
        "r = run_eda()\n",
        "print(\"Rows:\", r[\"rows\"])\n",
        "print(\"Plots:\", r.get(\"plot_paths\", []))\n",
        "print(\"Top keywords:\", list(r.get(\"top_keywords\", {}).keys())[:8])\n",
        "print(\"Practical insights:\", r.get(\"practical_insights\", {}))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Modeling: Churn and Segmentation\n",
        "\n",
        "- **Churn:** Logistic Regression and Naive Bayes with K-Fold CV; Precision, Recall, F1. Interpretability via coefficients (Logistic) and feature importance.\n",
        "- **Segmentation:** K-Means (2–3 clusters) on order_count and total_amount.\n",
        "- **Sentiment:** VADER in transform; optional pre-trained Hugging Face sentiment if installed."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from scripts.models import run_all_models\n",
        "\n",
        "summary = run_all_models()\n",
        "print(\"Churn F1 (Logistic):\", summary.get(\"churn\", {}).get(\"logistic\", {}).get(\"f1\"))\n",
        "print(\"Churn F1 (Naive Bayes):\", summary.get(\"churn\", {}).get(\"naive_bayes\", {}).get(\"f1\"))\n",
        "print(\"Segmentation:\", summary.get(\"segmentation\", {}))\n",
        "if summary.get(\"churn\", {}).get(\"logistic\", {}).get(\"feature_importance\"):\n",
        "    print(\"Feature importance (churn):\", summary[\"churn\"][\"logistic\"][\"feature_importance\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Key Insights and Recommendations\n",
        "\n",
        "- **Sentiment:** Use VADER scores from feedback to prioritize negative reviews.\n",
        "- **Churn:** Logistic Regression and Naive Bayes give interpretable signals; more orders and higher total amount tend to reduce churn.\n",
        "- **Segmentation:** K-Means on order_count/total_amount identifies low/medium/high value segments for targeted campaigns.\n",
        "- **Limitations:** Synthetic data; real deployment needs more data and optional pre-trained sentiment (e.g. Hugging Face)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Key visualizations (2–3 main insights)\n",
        "\n",
        "Below: customer sentiment distribution, segment distribution, and one relationship plot (scatter or trend)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from IPython.display import Image, display\n",
        "from pathlib import Path\n",
        "root = Path(\"..\") if Path.cwd().name == \"notebooks\" else Path(\".\")\n",
        "plots_dir = root / \"data\" / \"processed\" / \"plots\"\n",
        "key_plots = [\"sentiment_distribution.png\", \"segment_distribution.png\", \"scatter_wordcount_sentiment.png\"]\n",
        "for name in key_plots:\n",
        "    p = plots_dir / name\n",
        "    if p.exists():\n",
        "        display(Image(filename=str(p.resolve()), width=500))\n",
        "        print(p.name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Practical insights (answers to business questions)\n",
        "\n",
        "- **What topics were discussed most?** → Top keywords from EDA.\n",
        "- **What sentiment towards similar products?** → Sentiment distribution and mean compound score.\n",
        "- **Any pattern in time of interactions?** → Peak month and trend line.\n",
        "- **Which data source gave better insights?** → Counts by source_type (internal vs public)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Print practical insights from EDA (run EDA cell first)\n",
        "insights = r.get(\"practical_insights\", {})\n",
        "for k, v in insights.items():\n",
        "    print(f\"{k}: {v}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Project story (challenges, approach, findings, recommendations)\n",
        "\n",
        "**Challenges:** Noisy and scattered data (missing values, mixed formats); limited internal data; need for interpretable models.\n",
        "\n",
        "**Approach:** Modular ETL (separate scripts per source); iterative cleaning and NLTK for text; single source of truth; robust models (Logistic, Naive Bayes, K-Means) with K-Fold CV and Precision/Recall/F1.\n",
        "\n",
        "**Findings:** Sentiment from VADER helps prioritize negative feedback; churn is driven by order count and total amount; segmentation yields 2–3 actionable customer groups.\n",
        "\n",
        "**Recommendations:** Target high-value segments for retention; use sentiment to avoid pushing dissatisfied customers; collect more structured data and consider pre-trained Hugging Face sentiment for richer text analysis.\n",
        "\n",
        "**Limitations and next steps:** Data is synthetic; real deployment needs live APIs and more history. Improve by gathering better data and optional weather/events features."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Display one key plot path\n",
        "from config import DATA_PROCESSED\n",
        "plots_dir = DATA_PROCESSED / \"plots\"\n",
        "if plots_dir.exists():\n",
        "    for p in plots_dir.glob(\"*.png\"):\n",
        "        print(p)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
