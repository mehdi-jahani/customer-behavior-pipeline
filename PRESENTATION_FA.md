# متن ارائه پروژه — تحلیل رفتار مشتری و پیش‌بینی ریزش

**مخاطب:** مدیر بخش  
**هدف:** آشنایی کامل با سناریو، سوالات، پاسخ‌ها، روش‌های استفاده‌شده و دلیل عدم استفاده از روش‌های رقیب  
**مرجع سناریو:** `test.md`

---

## ۱. معرفی پروژه

این پروژه بر اساس سناریوی تعریف‌شده در **فایل test.md** طراحی و پیاده‌سازی شده است.

**سناریو (طبق test.md):**  
یک فروشگاه آنلاین کوچک فرضی که محصولات دست‌ساز می‌فروشد؛ منابع محدود و داده‌های مشتریان پراکنده و ناقص است.

**هدف پروژه:**  
با همین داده‌های محدود و نویزی، بینش عملی برای کسب‌وکار استخراج کنیم و ریزش مشتری را پیش‌بینی کنیم.

**خلاصه سناریو و هدف در کجا آمده است:**  
در **README.md** (بخش Scenario) و در **test.md** (ابتدای فایل).

---

## ۲. سوالات کلیدی و پاسخ کامل

طبق **test.md** چهار سوال اصلی مطرح شده است. پاسخ هر کدام در ادامه آمده است؛ در هر بخش روش استفاده‌شده، دلیل آن و دلیل عدم استفاده از روش‌های رقیب هم توضیح داده می‌شود.

---

### سوال ۱: چه عواملی روی علاقه مشتریان به محصولات ما تأثیر می‌گذارد؟

**پاسخ:**

- **احساسات (Sentiment):**  
  با تحلیل احساسات روی متن بازخوردها می‌فهمیم کدام نظرات منفی و کدام مثبت‌اند؛ امتیاز منفی یعنی احتمال نارضایتی و نیاز به پیگیری.

- **کلمات کلیدی:**  
  پرتکرارترین کلمات (مثل محصول، ارسال، طراحی) استخراج می‌شوند؛ نشان می‌دهند مشتریان روی چه موضوعاتی حساس‌اند.

- **منبع داده:**  
  با مقایسه دادهٔ داخلی (بازخورد مستقیم) و دادهٔ عمومی (مثل دیتاست احساسات) ترکیب هر دو بینش بهتری می‌دهد.

**روش استفاده‌شده و محل پیاده‌سازی:**  
تحلیل احساسات با
VADER
(در فایل
scripts/transform.py
داخل تابع
add_text_features
).  
کلمات کلیدی با تابع
keyword_frequency
در
scripts/eda.py
.  
مقایسه منابع با نمودار
source_type_counts
در
scripts/eda.py
.  
خلاصه در **SUMMARY.md** (Key Insights) و در نوت‌بوک **notebooks/01_full_pipeline.ipynb** (بخش Practical insights).

**چرا این روش‌ها:**  
VADER داخل NLTK است، بدون نیاز به GPU، و برای متن کوتاه و محاوره‌ای (نظرات) مناسب است.  
کلمات کلیدی با شمارش ساده و سریع به‌دست می‌آیند و برای دادهٔ کم کافی‌اند.

**چرا روش رقیب استفاده نشد:**  
برای احساسات، مدل‌های بزرگتر (مثل Hugging Face) دقیق‌ترند ولی برای دیتاست کوچک و اجرای سبک، VADER کافی است؛ مدل Hugging Face به‌صورت اختیاری در
scripts/models.py
در تابع
run_pretrained_sentiment_if_available
در دسترس است اگر نصب باشد.

---

### سوال ۲: چطور مشتریان بالقوه را پیدا کنیم؟

**پاسخ:**

- **بخش‌بندی (Segmentation):**  
  با **K-Means** مشتریان به چند گروه (کم‌خرید، میان‌خرید، پرخرید) تقسیم می‌شوند؛ گروه‌هایی که هنوز خرید کمی دارند یا از کانال‌های خاص می‌آیند می‌توانند مشتری بالقوه باشند.

- **منابع عمومی:**  
  پست‌های Reddit و محتوای وب افرادی را نشان می‌دهند که دربارهٔ محصولات دست‌ساز حرف می‌زنند؛ مخاطب بالقوه برای بازاریابی.

**روش استفاده‌شده و محل پیاده‌سازی:**  
بخش‌بندی با
K-Means
در
scripts/models.py
(تابع
run_segmentation
).  
خروجی در فایل
data/processed/customers_with_segments.csv
و نمودار
data/processed/plots/segment_distribution.png
.  
استخراج Reddit و وب در **scripts/extract_reddit_api.py** و **scripts/extract_web.py**.  
جزئیات در **SUMMARY.md** (Customer segments).

**چرا K-Means:**  
ساده، سریع و تعداد خوشه را ما تعیین می‌کنیم؛ برای «۲ یا ۳ خوشهٔ قابل تفسیر» ایده‌آل است و **test.md** صریحاً آن را خواسته است.

**چرا روش رقیب استفاده نشد:**  
روش‌هایی مثل
DBSCAN
یا خوشه‌بندی سلسله‌مراتبی یا نیاز به تنظیم پارامتر بیشتر دارند یا تفسیر خوشه‌ها سخت‌تر است؛ برای این سناریو
K-Means
کافی بود.

---

### سوال ۳: چه پیام‌های بازاریابی برای بخش‌های مختلف مشتری مؤثرتر است؟

**پاسخ:**

- **تفکیک بر اساس بخش:**  
  برای بخش با ارزش بالا (پرخرید) پیام حفظ و وفاداری؛ برای بخش متوسط پیام ارتقا (upsell)؛ برای بخش کم‌خرید یا بدون خرید اخیر پیام بازگرداندن (reactivation).

- **تفکیک بر اساس احساسات:**  
  برای کسانی که اخیراً نظر منفی داده‌اند نباید فشار بازاریابی زیاد باشد؛ اول رفع نارضایتی، بعد پیشنهاد جدید.

- **محتوا:**  
  با توجه به کلمات کلیدی پرتکرار (کیفیت، طراحی، ارسال) پیام‌ها حول همین موضوعات طراحی شوند.

**محل پیاده‌سازی و مستندات:**  
این توصیه‌ها از خروجی بخش‌بندی و احساسات استخراج شده و در **SUMMARY.md** (Practical Recommendations – Marketing و Content) نوشته شده‌اند.

---

### سوال ۴: چطور ریزش مشتری را با داده‌های محدود پیش‌بینی کنیم؟

**ایدهٔ کلی:**  
می‌خواهیم قبل از اینکه مشتری واقعاً ما را ترک کند، احتمال ریزش او را تخمین بزنیم تا بتوانیم با اقدام به‌موقع (مثلاً تماس یا پیشنهاد ویژه) جلوی از دست رفتن او را بگیریم. چون دادهٔ ما کم و پراکنده است، از مدل‌های ساده و قابل‌فهم استفاده کرده‌ایم تا هم نتیجهٔ معقول بگیریم هم بتوانیم به مدیر بگوییم «دلیلش چیست».

---

**۱. ریزش یعنی چه؟**  
در این پروژه مشتری **ریزش‌شده** کسی است که در **۱۲۰ روز گذشته** هیچ سفارشی نگذاشته باشد. یعنی اگر چهار ماه است خرید نکرده، او را در دستهٔ «ریزش‌شده» قرار می‌دهیم و مدل یاد می‌گیرد الگوی چنین مشتریانی چه شکلی است.

---

**۲. از چه چیزهایی استفاده می‌کنیم؟ (ویژگی‌ها)**  
برای هر مشتری چند عدد و دسته به مدل می‌دهیم تا بر اساس آن‌ها پیش‌بینی کند: تعداد سفارش‌ها، مبلغ کل خرید، روز هفته و ماه و فصلی که بیشتر خریده، کانال (مثلاً موبایل یا دسکتاپ) و منطقه. این‌ها همان چیزهایی هستند که در دادهٔ محدود ما وجود دارند و می‌توانند با «تمایل به ماندن یا رفتن» ارتباط داشته باشند.

---

**۳. چه مدل‌هایی استفاده شده؟**  
دو مدل در کنار هم آموزش داده و مقایسه شده‌اند:

- **رگرسیون لجستیک (Logistic Regression):** مدلی خطی و ساده که به هر ویژگی یک ضریب می‌دهد. مثلاً می‌گوید «هرچه تعداد سفارش کمتر، احتمال ریزش بیشتر» یا «مشتریان منطقهٔ X بیشتر ریزش می‌کنند». این ضرایب دقیقاً به ما می‌گویند کدام عامل بیشتر روی ریزش اثر دارد؛ یعنی **تفسیرش برای مدیر راحت است**.
- **Naive Bayes:** مدل دیگری که بر اساس احتمال کار می‌کند، ساده است و در برابر دادهٔ نویزی و ناقص مقاوم‌تر است. آن را کنار رگرسیون لجستیک گذاشتیم تا ببینیم هر دو در شرایط دادهٔ کم چطور عمل می‌کنند.

هر دو مدل با **Cross-Validation** (تقسیم داده به چند بخش و ارزیابی چندباره) تست شده‌اند تا با دادهٔ کم، نتیجه تصادفی نباشد و قابل اعتمادتر باشد.

---

**۴. چطور مدل را ارزیابی می‌کنیم؟**  
به‌جای اینکه فقط «درصد درست بودن کلی» (accuracy) را ببینیم، از سه معیار استفاده می‌کنیم:

- **Precision (دقت):** از بین کسانی که مدل گفته «ریزش می‌کنند»، چند نفر واقعاً ریزش کرده‌اند؟
- **Recall (بازخوانی):** از بین همهٔ کسانی که واقعاً ریزش کرده‌اند، مدل چند نفر را درست شناسایی کرده؟
- **F1:** ترکیبی از این دو که نشان می‌دهد مدل روی کلاس «ریزش‌شده» چقدر متعادل عمل می‌کند.

**چرا فقط accuracy کافی نیست؟** در مسئلهٔ ریزش معمولاً تعداد مشتریان ریزش‌شده کمتر از بقیه است. در این حالت یک مدل می‌تواند با پیش‌بینی «همه سالم‌اند» accuracy بالایی بگیرد ولی در عمل هیچ ریزشی را تشخیص ندهد. Precision و Recall و F1 دقیقاً نشان می‌دهند مدل روی همان گروه اقلیت (ریزش‌شده‌ها) چقدر خوب است.

---

**۵. کجا پیاده شده و خروجی کجاست؟**  
- تعریف «چه کسی ریزش‌شده» در تابع **build_churn_dataset** در فایل **scripts/models.py** انجام می‌شود.  
- آموزش دو مدل در تابع **train_churn_models** در همان فایل.  
- مدل‌های ذخیره‌شده (برای استفادهٔ بعدی) در پوشه **data/processed/models/** با پسوند **joblib**.  
- خلاصهٔ نتایج و معیارها در **SUMMARY.md** در بخش **Churn prediction**.

---

**۶. چرا این دو مدل و نه مدل‌های قوی‌تر؟**

- **چرا رگرسیون لجستیک؟**  
  ضرایب آن قابل تفسیرند؛ با دادهٔ کم هم معمولاً خوب کار می‌کند و کمتر از مدل‌های خیلی پیچیده دچار **overfitting** (یادگیری بیش از حد از دادهٔ کم و ضعیف شدن روی دادهٔ جدید) می‌شود. سناریو (**test.md**) هم صریحاً برای پیش‌بینی ریزش با دادهٔ کم این مدل را پیشنهاد کرده است.

- **چرا Naive Bayes در کنار آن؟**  
  ساده و مقاوم در برابر نویز است؛ **test.md** به‌دلیل «سادگی و مقاومت در برابر دادهٔ نویزی» آن را خواسته است.

- **چرا از Random Forest یا XGBoost استفاده نشد؟**  
  با حجم کم داده، این مدل‌ها راحت‌تر overfit می‌کنند و به‌سختی می‌شود گفت «کدام ویژگی دقیقاً چقدر اثر داشت». در این سناریو مدیر باید بتواند بفهمد **چرا** این مشتری در معرض ریزش است؛ پس تفسیرپذیری و عملکرد با دادهٔ کم اولویت داشت، نه پیچیدگی بیشتر.

---

## ۳. معماری پروژه (خلاصه)

- **config.py:**  
  مسیرها و بارگذاری کلیدهای API از `.env` (مثلاً برای Reddit).

- **scripts:**  
  هر منبع داده یک اسکریپت جدا دارد تا پایپ‌لاین انعطاف‌پذیر و قابل نگهداری باشد.

- **data/raw:**  
  دادهٔ خام (CSV و JSON).

- **data/processed:**  
  دادهٔ پاک‌شده، منبع واحد حقیقت، نمودارها و مدل‌ها.

ساختار کامل در **README.md** (Repository Structure) و **PROJECT_GUIDE_FA.md** (جدول ساختار پوشه‌ها) است.

---

## ۴. استخراج داده — روش‌ها و دلیل انتخاب

**چه کردیم:**  
برای هر منبع (داخلی، احساسات عمومی، وب، Reddit، CSV دلخواه) یک اسکریپت جدا نوشته شد؛ خروجی در **data/raw** به صورت CSV یا JSON ذخیره می‌شود.  
مرجع: **scripts/extract_synthetic.py**, **extract_public_dataset.py**, **extract_web.py**, **extract_reddit_api.py**, **extract_from_csv.py** و **PROJECT_GUIDE_FA.md** (بخش استخراج).

**چرا اسکریپت جدا برای هر منبع:**  
اگر یک منبع خطا بدهد یا موقتاً قطع شود، بقیهٔ پایپ‌لاین تحت تأثیر مستقیم قرار نمی‌گیرد؛ تست و تغییر هر منبع راحت‌تر است. مطابق **test.md**: «اسکریپت‌های پایتون کوچک و قابل مدیریت برای هر منبع».

**چرا برای وب از BeautifulSoup استفاده شد:**  
سبک و بدون وابستگی سنگین؛ برای استخراج متن از چند صفحه کافی است.

**چرا از Scrapy استفاده نشد:**  
برای پروژهٔ کوچک و تعداد کم
URL
لازم نبود و پیچیدگی اضافه می‌کرد.

**چرا برای Reddit هم API و هم دادهٔ نمونه:**  
با کلید API در `.env` داده واقعی از Reddit گرفته می‌شود. بدون کلید، تابع
sample_reddit_like_data
در
scripts/extract_reddit_api.py
پست‌های نمونه ذخیره می‌کند تا کل پایپ‌لاین بدون وابستگی به شبکه هم قابل اجرا باشد (جمع‌آوری آفلاین طبق **test.md**).

---

## ۵. تبدیل و پاکسازی — روش‌ها و دلیل انتخاب

همهٔ منطق در **scripts/transform.py** است؛ جزئیات توابع در **PROJECT_GUIDE_FA.md** (بخش تبدیل).

**دادهٔ عددی گمشده — چرا میانه (median) نه میانگین (mean):**  
در دادهٔ نویزی مقدارهای افراطی زیاد هستند؛ میانگین به‌راحتی منحرف می‌شود. میانه در برابر این مقادیر مقاوم‌تر است. در کد با تابع
fill_missing_numeric
و پارامتر
strategy="median"
.

**حذف ردیف‌های ناقص — چرا با «احتیاط» و با min_fill_ratio:**  
حذف هر ردیفی که حتی یک مقدار خالی دارد باعث از دست رفتن زیاد داده می‌شود. تابع
drop_rows_missing_key_columns
فقط ردیف‌هایی را حذف می‌کند که نسبت ستون‌های کلیدی پر شده‌شان از حد معین (مثلاً ۰.۵) کمتر باشد. مطابق **test.md**: «حذف ردیف‌هایی که اطلاعات کلیدی‌شان را ندارند (با احتیاط)».

**متن — چرا Stemming به‌صورت پیش‌فرض و Lemmatization اختیاری:**  
Stemming (Porter) سریع و بدون نیاز به دیکشنری؛ برای متن کوتاه و نظرات کافی است. Lemmatization (WordNet) دقیق‌تر ولی کندتر؛ به‌صورت اختیاری در تابع
transform_feedback
با پارامتر
use_lemmatize=True
قابل استفاده است. **test.md** هر دو را مجاز دانسته؛ پیش‌فرض Stemming برای اجرای سبک‌تر انتخاب شد.

**احساسات متن — چرا VADER و Hugging Face اختیاری:**  
VADER داخل NLTK، بدون GPU، مناسب متن کوتاه و محاوره‌ای. Hugging Face (مدل از پیش‌آموزش‌دیده) دقیق‌تر ولی نیاز به نصب transformers و حافظهٔ بیشتر؛ در تابع
run_pretrained_sentiment_if_available
در
scripts/models.py
در صورت نصب استفاده می‌شود. مطابق **test.md** برای احساسات در صورت نداشتن دیتاست بزرگ، مدل از پیش‌آموزش‌دیده پیشنهاد شده؛ هر دو پوشش داده شده‌اند.

**چرا یک Single Source of Truth:**  
همهٔ دادهٔ پاک‌شده (بازخورد داخلی + احساسات عمومی) در یک جدول واحد جمع می‌شود تا تحلیل و مدل‌سازی فقط روی یک منبع انجام شود. خروجی در فایل‌های
data/processed/single_source_of_truth.csv
و
single_source_of_truth.parquet
.

---

## ۶. مدل‌سازی — روش‌ها و دلیل انتخاب

همهٔ مدل‌ها در **scripts/models.py**؛ خلاصه در **SUMMARY.md** (Key Insights) و **CHECKLIST_TEST_MD.md** (Phase 4).

**ارزیابی — چرا K-Fold Cross-Validation و چرا ۳-fold:**  
با دادهٔ کم، یک تقسیم train/test ثابت ممکن است تصادفی باشد؛ با CV چند بار ارزیابی می‌شود و نتیجه پایدارتر است. ۳-fold انتخاب شده تا در هر بار به‌اندازهٔ کافی داده برای آموزش باقی بماند؛ با ۵ یا ۱۰ fold در دادهٔ خیلی کم هر fold خیلی کوچک می‌شود.

---

## ۷. تحلیل اکتشافی و بصری‌سازی

همه در **scripts/eda.py**؛ نمودارها در **data/processed/plots/** و توضیح هر نمودار در **SUMMARY.md** (جدول Key Visualizations).

- **هیستوگرام:** توزیع احساسات و طول متن (تعداد کلمات).
- **نمودار میله‌ای:** مقایسه منبع داده، تعداد بازخورد به تفکیک ماه، توزیع بخش‌ها.
- **نمودار خطی:** روند تعاملات در زمان.
- **پراکندگی (scatter):** رابطهٔ طول متن با امتیاز احساسات.
- **جعبه‌ای (boxplot):** شناسایی نویز و مقدارهای افراطی در احساسات.

**test.md** همین نوع نمودارها را خواسته و استفاده از آن‌ها برای شناسایی نویز. تابع
get_practical_insights
در
scripts/eda.py
پاسخ سوالات عملی (موضوعات، احساس، الگوی زمانی، بهترین منبع) را می‌سازد.

---

## ۸. گزارش زنده و مستندات

- **notebooks/01_full_pipeline.ipynb:**  
  گزارش زنده از استخراج تا مدل و نمودارها و داستان پروژه (چالش‌ها، رویکرد، یافته‌ها، پیشنهادات).

- **README.md:**  
  سناریو، ساختار، دستورات اجرا، چالش‌ها، یافته‌ها، محدودیت‌ها.

- **SUMMARY.md:**  
  بینش‌های کلیدی، توصیه‌های عملی، محدودیت‌ها، جدول نمودارهای کلیدی (مطابق خواستهٔ test.md برای «فایل خلاصه»).

- **PROJECT_GUIDE_FA.md:**  
  راهنمای فنی کامل به فارسی (توابع، پارامترها، مسیر فایل‌ها).

- **CHECKLIST_TEST_MD.md:**  
  تطابق هر الزام test.md با پیاده‌سازی (فایل/تابع).

---

## ۹. جمع‌بندی برای مدیر

- **مسئله و سوالات:** در **test.md** تعریف شده‌اند؛ پاسخ هر سوال در تحلیل و مدل‌ها پیاده شده و در **SUMMARY.md** و نوت‌بوک خلاصه شده است.

- **داده:** استخراج از چند منبع با اسکریپت‌های جدا؛ ذخیرهٔ استاندارد (CSV, JSON) برای استفادهٔ آفلاین.

- **پاکسازی:** پاکسازی تکراری، میانه برای عددی، حذف احتیاطی ردیف، Stemming و VADER و در صورت نیاز Lemmatization و مدل Hugging Face؛ یک منبع واحد حقیقت.

- **مدل‌سازی:** ریزش با دو مدل تفسیرپذیر (Logistic Regression و Naive Bayes) و مقاوم در برابر نویز؛ بخش‌بندی با K-Means؛ ارزیابی با
  CV
  و
  Precision/Recall/F1
  ؛ ذخیرهٔ مدل‌ها در پوشه
  data/processed/models/
  برای استفادهٔ بعدی.

- **مستندات:** README، SUMMARY، راهنمای فارسی (PROJECT_GUIDE_FA.md)، چک‌لیست تطابق با test.md و نوت‌بوک گزارش زنده.

با مطالعهٔ این متن و در صورت نیاز مراجعه به فایل‌های نام‌برده شده، تصویر کامل از سناریو، روش‌ها، دلیل انتخاب‌ها، دلیل عدم استفاده از روش‌های رقیب و پاسخ سوالات برای مدیر بخش فراهم می‌شود.

---

*منبع: test.md, README.md, SUMMARY.md, PROJECT_GUIDE_FA.md, CHECKLIST_TEST_MD.md و کد در scripts/ و notebooks/01_full_pipeline.ipynb.*
