# متن ارائه پروژه — تحلیل رفتار مشتری و پیش‌بینی ریزش

**مخاطب:** مدیر بخش  
**هدف:** آشنایی کامل با سناریو، سوالات، پاسخ‌ها، روش‌های استفاده‌شده و دلیل عدم استفاده از روش‌های رقیب  
**مرجع سناریو:** `test.md`

---

## ۱. معرفی پروژه

این پروژه بر اساس سناریوی تعریف‌شده در **فایل test.md** طراحی و پیاده‌سازی شده است.

**سناریو (طبق test.md):**  
یک فروشگاه آنلاین کوچک فرضی که محصولات دست‌ساز می‌فروشد؛ منابع محدود و داده‌های مشتریان پراکنده و ناقص است.

**هدف پروژه:**  
با همین داده‌های محدود و نویزی، بینش عملی برای کسب‌وکار استخراج کنیم و ریزش مشتری را پیش‌بینی کنیم.

**خلاصه سناریو و هدف در کجا آمده است:**  
در **README.md** (بخش Scenario) و در **test.md** (ابتدای فایل).

---

## ۲. سوالات کلیدی و پاسخ کامل

طبق **test.md** چهار سوال اصلی مطرح شده است. پاسخ هر کدام در ادامه آمده است؛ در هر بخش روش استفاده‌شده، دلیل آن و دلیل عدم استفاده از روش‌های رقیب هم توضیح داده می‌شود.

---

### سوال ۱: چه عواملی روی علاقه مشتریان به محصولات ما تأثیر می‌گذارد؟

**پاسخ:**

- **احساسات (Sentiment):**  
  با تحلیل احساسات روی متن بازخوردها می‌فهمیم کدام نظرات منفی و کدام مثبت‌اند؛ امتیاز منفی یعنی احتمال نارضایتی و نیاز به پیگیری.

- **کلمات کلیدی:**  
  پرتکرارترین کلمات (مثل محصول، ارسال، طراحی) استخراج می‌شوند؛ نشان می‌دهند مشتریان روی چه موضوعاتی حساس‌اند.

- **منبع داده:**  
  با مقایسه دادهٔ داخلی (بازخورد مستقیم) و دادهٔ عمومی (مثل دیتاست احساسات) ترکیب هر دو بینش بهتری می‌دهد.

**روش استفاده‌شده و محل پیاده‌سازی:**  
تحلیل احساسات با
VADER
(در فایل
scripts/transform.py
داخل تابع
add_text_features
).  
کلمات کلیدی با تابع
keyword_frequency
در
scripts/eda.py
.  
مقایسه منابع با نمودار
source_type_counts
در
scripts/eda.py
.  
خلاصه در **SUMMARY.md** (Key Insights) و در نوت‌بوک **notebooks/01_full_pipeline.ipynb** (بخش Practical insights).

**چرا این روش‌ها:**  
VADER داخل NLTK است، بدون نیاز به GPU، و برای متن کوتاه و محاوره‌ای (نظرات) مناسب است.  
کلمات کلیدی با شمارش ساده و سریع به‌دست می‌آیند و برای دادهٔ کم کافی‌اند.

**چرا روش رقیب استفاده نشد:**  
برای احساسات، مدل‌های بزرگتر (مثل Hugging Face) دقیق‌ترند ولی برای دیتاست کوچک و اجرای سبک، VADER کافی است؛ مدل Hugging Face به‌صورت اختیاری در
scripts/models.py
در تابع
run_pretrained_sentiment_if_available
در دسترس است اگر نصب باشد.

---

### سوال ۲: چطور مشتریان بالقوه را پیدا کنیم؟

**پاسخ:**

- **بخش‌بندی (Segmentation):**  
  با **K-Means** مشتریان به چند گروه (کم‌خرید، میان‌خرید، پرخرید) تقسیم می‌شوند؛ گروه‌هایی که هنوز خرید کمی دارند یا از کانال‌های خاص می‌آیند می‌توانند مشتری بالقوه باشند.

- **منابع عمومی:**  
  پست‌های Reddit و محتوای وب افرادی را نشان می‌دهند که دربارهٔ محصولات دست‌ساز حرف می‌زنند؛ مخاطب بالقوه برای بازاریابی.

**روش استفاده‌شده و محل پیاده‌سازی:**  
بخش‌بندی با
K-Means
در
scripts/models.py
(تابع
run_segmentation
).  
خروجی در فایل
data/processed/customers_with_segments.csv
و نمودار
data/processed/plots/segment_distribution.png
.  
استخراج Reddit و وب در **scripts/extract_reddit_api.py** و **scripts/extract_web.py**.  
جزئیات در **SUMMARY.md** (Customer segments).

**چرا K-Means:**  
ساده، سریع و تعداد خوشه را ما تعیین می‌کنیم؛ برای «۲ یا ۳ خوشهٔ قابل تفسیر» ایده‌آل است و **test.md** صریحاً آن را خواسته است.

**چرا روش رقیب استفاده نشد:**  
روش‌هایی مثل
DBSCAN
یا خوشه‌بندی سلسله‌مراتبی یا نیاز به تنظیم پارامتر بیشتر دارند یا تفسیر خوشه‌ها سخت‌تر است؛ برای این سناریو
K-Means
کافی بود.

---

### سوال ۳: چه پیام‌های بازاریابی برای بخش‌های مختلف مشتری مؤثرتر است؟

**پاسخ:**

- **تفکیک بر اساس بخش:**  
  برای بخش با ارزش بالا (پرخرید) پیام حفظ و وفاداری؛ برای بخش متوسط پیام ارتقا (upsell)؛ برای بخش کم‌خرید یا بدون خرید اخیر پیام بازگرداندن (reactivation).

- **تفکیک بر اساس احساسات:**  
  برای کسانی که اخیراً نظر منفی داده‌اند نباید فشار بازاریابی زیاد باشد؛ اول رفع نارضایتی، بعد پیشنهاد جدید.

- **محتوا:**  
  با توجه به کلمات کلیدی پرتکرار (کیفیت، طراحی، ارسال) پیام‌ها حول همین موضوعات طراحی شوند.

**محل پیاده‌سازی و مستندات:**  
این توصیه‌ها از خروجی بخش‌بندی و احساسات استخراج شده و در **SUMMARY.md** (Practical Recommendations – Marketing و Content) نوشته شده‌اند.

---

### سوال ۴: چطور ریزش مشتری را با داده‌های محدود پیش‌بینی کنیم؟

**پاسخ:**

- **تعریف ریزش:**  
  مشتری که در ۱۲۰ روز اخیر هیچ سفارشی نداشته باشد «ریزش‌شده» در نظر گرفته می‌شود.

- **ویژگی‌ها:**  
  تعداد سفارش، مبلغ کل، روز هفته، ماه، فصل، کانال و منطقه.

- **مدل‌ها:**  
  دو مدل برای مقایسه و تفسیر: رگرسیون لجستیک و Naive Bayes؛ با Cross-Validation و معیارهای Precision، Recall و F1 ارزیابی می‌شوند.

- **تفسیر:**  
  ضرایب رگرسیون لجستیک (feature_importance) نشان می‌دهند کدام ویژگی بیشتر روی ریزش اثر دارد.

**روش استفاده‌شده و محل پیاده‌سازی:**  
تعریف ریزش در تابع
build_churn_dataset
در
scripts/models.py
.  
آموزش در تابع
train_churn_models
.  
خروجی مدل‌ها در پوشه
data/processed/models/
(فایل‌های
joblib
).  
خلاصه در
SUMMARY.md
بخش Churn prediction.

**چرا Logistic Regression:**  
ضرایب مدل قابل تفسیر هستند؛ با دادهٔ کم هم خوب کار می‌کند و overfitting کمتر از مدل‌های پیچیده‌تر است. **test.md** صریحاً آن را برای ریزش با دادهٔ کم پیشنهاد کرده است.

**چرا Naive Bayes در کنار آن:**  
ساده و مقاوم در برابر نویز؛ **test.md** آن را به‌دلیل «سادگی و مقاومت در برابر دادهٔ نویزی» خواسته است.

**چرا از Random Forest یا XGBoost استفاده نشد:**  
با حجم کم داده، این مدل‌ها راحت‌تر
overfit
می‌کنند و تفسیرپذیری کمتری دارند؛ مدیر باید بتواند بفهمد «چرا» این مشتری ریزش‌شده. سناریو بر تفسیرپذیری و عملکرد با دادهٔ کم تأکید دارد.

**چرا Precision، Recall و F1 به‌جای فقط accuracy:**  
در مسئلهٔ ریزش معمولاً یک کلاس (ریزش‌شده) کمتر است؛ accuracy گمراه‌کننده است. Precision و Recall و F1 نشان می‌دهند مدل روی کلاس اقلیت چقدر خوب عمل می‌کند.

---

## ۳. معماری پروژه (خلاصه)

- **config.py:**  
  مسیرها و بارگذاری کلیدهای API از `.env` (مثلاً برای Reddit).

- **scripts:**  
  هر منبع داده یک اسکریپت جدا دارد تا پایپ‌لاین انعطاف‌پذیر و قابل نگهداری باشد.

- **data/raw:**  
  دادهٔ خام (CSV و JSON).

- **data/processed:**  
  دادهٔ پاک‌شده، منبع واحد حقیقت، نمودارها و مدل‌ها.

ساختار کامل در **README.md** (Repository Structure) و **PROJECT_GUIDE_FA.md** (جدول ساختار پوشه‌ها) است.

---

## ۴. استخراج داده — روش‌ها و دلیل انتخاب

**چه کردیم:**  
برای هر منبع (داخلی، احساسات عمومی، وب، Reddit، CSV دلخواه) یک اسکریپت جدا نوشته شد؛ خروجی در **data/raw** به صورت CSV یا JSON ذخیره می‌شود.  
مرجع: **scripts/extract_synthetic.py**, **extract_public_dataset.py**, **extract_web.py**, **extract_reddit_api.py**, **extract_from_csv.py** و **PROJECT_GUIDE_FA.md** (بخش استخراج).

**چرا اسکریپت جدا برای هر منبع:**  
اگر یک منبع خطا بدهد یا موقتاً قطع شود، بقیهٔ پایپ‌لاین تحت تأثیر مستقیم قرار نمی‌گیرد؛ تست و تغییر هر منبع راحت‌تر است. مطابق **test.md**: «اسکریپت‌های پایتون کوچک و قابل مدیریت برای هر منبع».

**چرا برای وب از BeautifulSoup استفاده شد:**  
سبک و بدون وابستگی سنگین؛ برای استخراج متن از چند صفحه کافی است.

**چرا از Scrapy استفاده نشد:**  
برای پروژهٔ کوچک و تعداد کم
URL
لازم نبود و پیچیدگی اضافه می‌کرد.

**چرا برای Reddit هم API و هم دادهٔ نمونه:**  
با کلید API در `.env` داده واقعی از Reddit گرفته می‌شود. بدون کلید، تابع
sample_reddit_like_data
در
scripts/extract_reddit_api.py
پست‌های نمونه ذخیره می‌کند تا کل پایپ‌لاین بدون وابستگی به شبکه هم قابل اجرا باشد (جمع‌آوری آفلاین طبق **test.md**).

---

## ۵. تبدیل و پاکسازی — روش‌ها و دلیل انتخاب

همهٔ منطق در **scripts/transform.py** است؛ جزئیات توابع در **PROJECT_GUIDE_FA.md** (بخش تبدیل).

**دادهٔ عددی گمشده — چرا میانه (median) نه میانگین (mean):**  
در دادهٔ نویزی مقدارهای افراطی زیاد هستند؛ میانگین به‌راحتی منحرف می‌شود. میانه در برابر این مقادیر مقاوم‌تر است. در کد با تابع
fill_missing_numeric
و پارامتر
strategy="median"
.

**حذف ردیف‌های ناقص — چرا با «احتیاط» و با min_fill_ratio:**  
حذف هر ردیفی که حتی یک مقدار خالی دارد باعث از دست رفتن زیاد داده می‌شود. تابع
drop_rows_missing_key_columns
فقط ردیف‌هایی را حذف می‌کند که نسبت ستون‌های کلیدی پر شده‌شان از حد معین (مثلاً ۰.۵) کمتر باشد. مطابق **test.md**: «حذف ردیف‌هایی که اطلاعات کلیدی‌شان را ندارند (با احتیاط)».

**متن — چرا Stemming به‌صورت پیش‌فرض و Lemmatization اختیاری:**  
Stemming (Porter) سریع و بدون نیاز به دیکشنری؛ برای متن کوتاه و نظرات کافی است. Lemmatization (WordNet) دقیق‌تر ولی کندتر؛ به‌صورت اختیاری در تابع
transform_feedback
با پارامتر
use_lemmatize=True
قابل استفاده است. **test.md** هر دو را مجاز دانسته؛ پیش‌فرض Stemming برای اجرای سبک‌تر انتخاب شد.

**احساسات متن — چرا VADER و Hugging Face اختیاری:**  
VADER داخل NLTK، بدون GPU، مناسب متن کوتاه و محاوره‌ای. Hugging Face (مدل از پیش‌آموزش‌دیده) دقیق‌تر ولی نیاز به نصب transformers و حافظهٔ بیشتر؛ در تابع
run_pretrained_sentiment_if_available
در
scripts/models.py
در صورت نصب استفاده می‌شود. مطابق **test.md** برای احساسات در صورت نداشتن دیتاست بزرگ، مدل از پیش‌آموزش‌دیده پیشنهاد شده؛ هر دو پوشش داده شده‌اند.

**چرا یک Single Source of Truth:**  
همهٔ دادهٔ پاک‌شده (بازخورد داخلی + احساسات عمومی) در یک جدول واحد جمع می‌شود تا تحلیل و مدل‌سازی فقط روی یک منبع انجام شود. خروجی در فایل‌های
data/processed/single_source_of_truth.csv
و
single_source_of_truth.parquet
.

---

## ۶. مدل‌سازی — روش‌ها و دلیل انتخاب

همهٔ مدل‌ها در **scripts/models.py**؛ خلاصه در **SUMMARY.md** (Key Insights) و **CHECKLIST_TEST_MD.md** (Phase 4).

**ارزیابی — چرا K-Fold Cross-Validation و چرا ۳-fold:**  
با دادهٔ کم، یک تقسیم train/test ثابت ممکن است تصادفی باشد؛ با CV چند بار ارزیابی می‌شود و نتیجه پایدارتر است. ۳-fold انتخاب شده تا در هر بار به‌اندازهٔ کافی داده برای آموزش باقی بماند؛ با ۵ یا ۱۰ fold در دادهٔ خیلی کم هر fold خیلی کوچک می‌شود.

---

## ۷. تحلیل اکتشافی و بصری‌سازی

همه در **scripts/eda.py**؛ نمودارها در **data/processed/plots/** و توضیح هر نمودار در **SUMMARY.md** (جدول Key Visualizations).

- **هیستوگرام:** توزیع احساسات و طول متن (تعداد کلمات).
- **نمودار میله‌ای:** مقایسه منبع داده، تعداد بازخورد به تفکیک ماه، توزیع بخش‌ها.
- **نمودار خطی:** روند تعاملات در زمان.
- **پراکندگی (scatter):** رابطهٔ طول متن با امتیاز احساسات.
- **جعبه‌ای (boxplot):** شناسایی نویز و مقدارهای افراطی در احساسات.

**test.md** همین نوع نمودارها را خواسته و استفاده از آن‌ها برای شناسایی نویز. تابع
get_practical_insights
در
scripts/eda.py
پاسخ سوالات عملی (موضوعات، احساس، الگوی زمانی، بهترین منبع) را می‌سازد.

---

## ۸. گزارش زنده و مستندات

- **notebooks/01_full_pipeline.ipynb:**  
  گزارش زنده از استخراج تا مدل و نمودارها و داستان پروژه (چالش‌ها، رویکرد، یافته‌ها، پیشنهادات).

- **README.md:**  
  سناریو، ساختار، دستورات اجرا، چالش‌ها، یافته‌ها، محدودیت‌ها.

- **SUMMARY.md:**  
  بینش‌های کلیدی، توصیه‌های عملی، محدودیت‌ها، جدول نمودارهای کلیدی (مطابق خواستهٔ test.md برای «فایل خلاصه»).

- **PROJECT_GUIDE_FA.md:**  
  راهنمای فنی کامل به فارسی (توابع، پارامترها، مسیر فایل‌ها).

- **CHECKLIST_TEST_MD.md:**  
  تطابق هر الزام test.md با پیاده‌سازی (فایل/تابع).

---

## ۹. جمع‌بندی برای مدیر

- **مسئله و سوالات:** در **test.md** تعریف شده‌اند؛ پاسخ هر سوال در تحلیل و مدل‌ها پیاده شده و در **SUMMARY.md** و نوت‌بوک خلاصه شده است.

- **داده:** استخراج از چند منبع با اسکریپت‌های جدا؛ ذخیرهٔ استاندارد (CSV, JSON) برای استفادهٔ آفلاین.

- **پاکسازی:** پاکسازی تکراری، میانه برای عددی، حذف احتیاطی ردیف، Stemming و VADER و در صورت نیاز Lemmatization و مدل Hugging Face؛ یک منبع واحد حقیقت.

- **مدل‌سازی:** ریزش با دو مدل تفسیرپذیر (Logistic Regression و Naive Bayes) و مقاوم در برابر نویز؛ بخش‌بندی با K-Means؛ ارزیابی با
  CV
  و
  Precision/Recall/F1
  ؛ ذخیرهٔ مدل‌ها در پوشه
  data/processed/models/
  برای استفادهٔ بعدی.

- **مستندات:** README، SUMMARY، راهنمای فارسی (PROJECT_GUIDE_FA.md)، چک‌لیست تطابق با test.md و نوت‌بوک گزارش زنده.

با مطالعهٔ این متن و در صورت نیاز مراجعه به فایل‌های نام‌برده شده، تصویر کامل از سناریو، روش‌ها، دلیل انتخاب‌ها، دلیل عدم استفاده از روش‌های رقیب و پاسخ سوالات برای مدیر بخش فراهم می‌شود.

---

*منبع: test.md, README.md, SUMMARY.md, PROJECT_GUIDE_FA.md, CHECKLIST_TEST_MD.md و کد در scripts/ و notebooks/01_full_pipeline.ipynb.*
